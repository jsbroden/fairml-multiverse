{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1346b9cb",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f58c32f",
   "metadata": {
    "papermill": {
     "duration": 0.006002,
     "end_time": "2025-04-24T19:03:17.686775",
     "exception": false,
     "start_time": "2025-04-24T19:03:17.680773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following cell holds the definition of our parameters,\n",
    "these values can be overriden by rendering the with e.g. the following command:\n",
    "\n",
    "```bash\n",
    "papermill -p alpha 0.2 -p ratio 0.3 universe_analysis.ipynb output/test_run.ipynb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c53745c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:03:17.701781Z",
     "iopub.status.busy": "2025-04-24T19:03:17.701117Z",
     "iopub.status.idle": "2025-04-24T19:03:17.712652Z",
     "shell.execute_reply": "2025-04-24T19:03:17.710873Z"
    },
    "papermill": {
     "duration": 0.023797,
     "end_time": "2025-04-24T19:03:17.716151",
     "exception": false,
     "start_time": "2025-04-24T19:03:17.692354",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "run_no = 0\n",
    "universe_id = \"test\"\n",
    "universe = {\n",
    "    \"model\": \"logreg\", # \"rf\", \"gbm\"\n",
    "    \"cutoff\": [\"quantile_0.15\", \"quantile_0.3\"],\n",
    "    \"exclude_features\": \"none\", # \"frau1\", \"maxdeutsch1\", \"maxdeutsch.Missing.\"\n",
    "}\n",
    "output_dir=\"./output\"\n",
    "seed=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110340d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:03:17.732245Z",
     "iopub.status.busy": "2025-04-24T19:03:17.731818Z",
     "iopub.status.idle": "2025-04-24T19:03:17.737130Z",
     "shell.execute_reply": "2025-04-24T19:03:17.735573Z"
    },
    "papermill": {
     "duration": 0.018851,
     "end_time": "2025-04-24T19:03:17.739686",
     "exception": false,
     "start_time": "2025-04-24T19:03:17.720835",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "universe_id = \"2d4dacc3da52d3763f77618153b1af95\"\n",
    "run_no = \"2\"\n",
    "universe = \"{\\\"cutoff\\\": [\\\"quantile_0.15\\\", \\\"quantile_0.3\\\"], \\\"exclude_features\\\": \\\"frau1\\\", \\\"model\\\": \\\"rf\\\"}\"\n",
    "output_dir = \"output\"\n",
    "seed = \"2023\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115beadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:03:17.747131Z",
     "iopub.status.busy": "2025-04-24T19:03:17.746917Z",
     "iopub.status.idle": "2025-04-24T19:03:17.751395Z",
     "shell.execute_reply": "2025-04-24T19:03:17.750170Z"
    },
    "papermill": {
     "duration": 0.010946,
     "end_time": "2025-04-24T19:03:17.753697",
     "exception": false,
     "start_time": "2025-04-24T19:03:17.742751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Parse universe into dict if it is passed as a string\n",
    "if isinstance(universe, str):\n",
    "    universe = json.loads(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd256654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:03:17.762700Z",
     "iopub.status.busy": "2025-04-24T19:03:17.762471Z",
     "iopub.status.idle": "2025-04-24T19:03:17.828509Z",
     "shell.execute_reply": "2025-04-24T19:03:17.827358Z"
    },
    "papermill": {
     "duration": 0.074521,
     "end_time": "2025-04-24T19:03:17.831112",
     "exception": false,
     "start_time": "2025-04-24T19:03:17.756591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Auto-reload the custom package\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport fairness_multiverse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78c972",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab72b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T19:03:17.838463Z",
     "iopub.status.busy": "2025-04-24T19:03:17.838244Z",
     "iopub.status.idle": "2025-04-24T19:03:18.571934Z",
     "shell.execute_reply": "2025-04-24T19:03:18.570592Z"
    },
    "papermill": {
     "duration": 0.739565,
     "end_time": "2025-04-24T19:03:18.573785",
     "exception": true,
     "start_time": "2025-04-24T19:03:17.834220",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfairness_multiverse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01muniverse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UniverseAnalysis\n\u001b[32m      3\u001b[39m universe_analysis = UniverseAnalysis(\n\u001b[32m      4\u001b[39m     run_no = run_no,\n\u001b[32m      5\u001b[39m     universe_id = universe_id,\n\u001b[32m      6\u001b[39m     universe = universe,\n\u001b[32m      7\u001b[39m     output_dir=output_dir,\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Master_Thesis/Example_Code/fairml-multiverse/fairness_multiverse/universe.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional, Any, Tuple\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionTransformer, KBinsDiscretizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from fairness_multiverse.universe import UniverseAnalysis\n",
    "\n",
    "universe_analysis = UniverseAnalysis(\n",
    "    run_no = run_no,\n",
    "    universe_id = universe_id,\n",
    "    universe = universe,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec02d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Always use the same seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe74108",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "parsed_seed = int(seed)\n",
    "np.random.seed(parsed_seed)\n",
    "print(f\"Using Seed: {parsed_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08031d45",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f131bad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": [
     "load-data"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the data\n",
    "data_path = 'Kern24_code/data/siab.csv'\n",
    "\n",
    "# Use custom caching of data (optional if you want to cache the synthetic data)\n",
    "#cache_dir = Path(\"data\")\n",
    "#cache_dir.mkdir(exist_ok=True)\n",
    "#cache_file = cache_dir / \"synthetic_dataset.csv.gz\"\n",
    "\n",
    "if Path(data_path).exists():\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "    dataset = pd.read_csv(data_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Data file not found at {data_path}\")\n",
    "\n",
    "# Optionally, cache the loaded dataset (if you want to save it for future use)\n",
    "#dataset.to_csv(cache_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65cc0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a4746",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "```\n",
    "# Invert the categories dictionary\n",
    "categories_inverted = {\n",
    "    column: {v: k for k, v in mapping.items()}\n",
    "    for column, mapping in categories.items()\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4bdec58",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Exclude Protected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f062a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note this will always be n >= 1, even if empty!\n",
    "excluded_features = universe[\"exclude_features\"].split(\"-\")\n",
    "excluded_features_dictionary = {\n",
    "    \"race\": \"RAC1P\",\n",
    "    \"sex\": \"SEX\",\n",
    "    \"immigration\": \"NATIVITY\",\n",
    "}\n",
    "\n",
    "# Code nice names to column names\n",
    "excluded_feature_columns = [\n",
    "    excluded_features_dictionary[f] for f in excluded_features if len(f) > 0 and f != \"none\"\n",
    "]\n",
    "\n",
    "if len(excluded_feature_columns) > 0:\n",
    "    print(f\"Dropping features: {excluded_feature_columns}\")\n",
    "    features.drop(excluded_feature_columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11bb9c9a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Continuous Variables: Binning / Log-Scaling / Keeping Them As-Is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8517e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from fairness_multiverse.universe import preprocess_continuous\n",
    "\n",
    "transformer_age, bins_age = preprocess_continuous(source_data=features, column_name=\"AGEP\", configuration=universe[\"preprocess_age\"])\n",
    "transformer_income, bins_income = preprocess_continuous(source_data=features, column_name=\"PINCP\", configuration=universe[\"preprocess_income\"])\n",
    "\n",
    "continuous_processor = make_pipeline(\n",
    "    transformer_age,\n",
    "    transformer_income\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a8beb2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Categorical Variables: One-Hot or Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7da117",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "all_categorical_columns = list(set(categories.keys()).intersection(set(features.columns)))\n",
    "\n",
    "# For which columns is ordinal encoding even an option?\n",
    "categorical_columns_to_transform = [\n",
    "    'SCHL',\n",
    "    # 'MAR',\n",
    "    # 'SEX',\n",
    "    # 'DIS',\n",
    "    # 'ESP',\n",
    "    # 'CIT',\n",
    "    # 'MIG',\n",
    "    'MIL',\n",
    "    # 'ANC',\n",
    "    # 'NATIVITY',\n",
    "    # 'DEAR',\n",
    "    # 'DEYE',\n",
    "    # 'DREM',\n",
    "    # 'ESR',\n",
    "    # 'ST',\n",
    "    # 'FER',\n",
    "    # 'RAC1P'\n",
    "]\n",
    "\n",
    "# Support to-be-binned continuous variables\n",
    "def add_binned_variable_to_categorical_transformation(colname, values):\n",
    "    if values is not None:\n",
    "        categorical_columns_to_transform.append(colname)\n",
    "        categories[colname] = {val: val for val in values}\n",
    "\n",
    "add_binned_variable_to_categorical_transformation(\"AGEP\", bins_age)\n",
    "add_binned_variable_to_categorical_transformation(\"PINCP\", bins_income)\n",
    "\n",
    "def nested_list(all_categories, columns_to_use):\n",
    "    categories = { col: all_categories[col] for col in columns_to_use }\n",
    "    # Create a nested list from the categories dict\n",
    "    categories_list = [[v for k, v in mapping.items()] for column, mapping in categories.items()]\n",
    "    return categories_list\n",
    "\n",
    "if (universe[\"encode_categorical\"] == \"ordinal\"):\n",
    "    categorical_transformer = OrdinalEncoder(\n",
    "        categories = nested_list(categories, categorical_columns_to_transform),\n",
    "    )\n",
    "elif (universe[\"encode_categorical\"] == \"one-hot\"):\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        categories = nested_list(categories, categorical_columns_to_transform),\n",
    "        sparse_output=False\n",
    "    )\n",
    "else:\n",
    "    raise \"Unsupported universe option for encode_categorical\"\n",
    "\n",
    "# One-Hot Encode all other cateogircal columns\n",
    "other_categorical_columns = list(set(all_categorical_columns) - set(categorical_columns_to_transform))\n",
    "other_transformer = OneHotEncoder(\n",
    "    categories = nested_list(categories, other_categorical_columns),\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "categorical_preprocessor = ColumnTransformer([\n",
    "        (\"encode_categorical\", categorical_transformer, categorical_columns_to_transform),\n",
    "        (\"encode_categorical_rest\", other_transformer, other_categorical_columns),\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a533a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b1a3e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select stratification strategy\n",
    "if universe[\"stratify_split\"] == \"none\":\n",
    "    stratify = None\n",
    "elif universe[\"stratify_split\"] == \"target\":\n",
    "    stratify = label\n",
    "elif universe[\"stratify_split\"] == \"protected-attribute\":\n",
    "    stratify = features_org[\"RAC1P\"]\n",
    "elif universe[\"stratify_split\"] == \"both\":\n",
    "    # Concatinate both columns\n",
    "    stratify = features_org[\"RAC1P\"].astype(str) + \"-\" + label[\"PUBCOV\"].astype(str)\n",
    "\n",
    "stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c57a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(\n",
    "    X_train, X_test,\n",
    "    y_train, y_true,\n",
    "    group_train, group_test,\n",
    "    org_train, org_test\n",
    ") = train_test_split(\n",
    "    features,\n",
    "    label,\n",
    "    group,\n",
    "    features_org,\n",
    "    test_size=0.2,\n",
    "    # Note: The analysis originally used two distinct seeds, one for numpy (defaulting to 2023) and one for the train_test_split (defaulting to 0).\n",
    "    # To allow for exact reproducibility of the original results, as well as specification of only a single seed we base this second seed off the first one.\n",
    "    # If you adapt this code for your own analysis feel free to remove this line and replace it e.g. with e.g. a call to numpy.random.randint.\n",
    "    random_state=abs(parsed_seed - 2023),\n",
    "    stratify=stratify\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f0e9037",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Post-Splitting Processing\n",
    "\n",
    "If e.g. only train data is affected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f46a11",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Exclude Certain Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303629b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract configuration\n",
    "exclude_subgroups_config = universe[\"exclude_subgroups\"].split(\"_\")\n",
    "if len(exclude_subgroups_config) == 1:\n",
    "    exclude_subgroups_config = (exclude_subgroups_config[0], None, None)\n",
    "excl_subgroups_method, excl_subgroup_colname, excl_subgroups_value = exclude_subgroups_config\n",
    "\n",
    "if excl_subgroup_colname == \"race\":\n",
    "    excl_subgroup_column = \"RAC1P\"\n",
    "    excl_subgroup_counts = org_train[excl_subgroup_column].value_counts()\n",
    "elif excl_subgroups_method != \"keep-all\":\n",
    "    raise Exception(\"Unsupported configuration for exclude_subgroups:\" + universe[\"exclude_subgroups\"])\n",
    "\n",
    "if excl_subgroups_method == \"keep-all\":\n",
    "    # Don't need to do anything\n",
    "    excl_subgroup_column = None\n",
    "    excl_subgroup_values = []\n",
    "else:\n",
    "    if excl_subgroups_method == \"drop-smallest\":\n",
    "        drop_smallest_n = int(excl_subgroups_value)\n",
    "        excl_subgroup_values = list(excl_subgroup_counts.tail(drop_smallest_n).index)\n",
    "    elif excl_subgroups_method == \"keep-largest\":\n",
    "        keep_largest_n = int(excl_subgroups_value)\n",
    "        excl_subgroup_values = list(excl_subgroup_counts.tail(\n",
    "            len(excl_subgroup_counts) - keep_largest_n\n",
    "        ).index)\n",
    "    elif excl_subgroups_method == \"drop-name\":\n",
    "        excl_subgroup_values = [excl_subgroups_value]\n",
    "    else:\n",
    "        raise Exception(\"Unsupported configuration for exclude_subgroups:\" + universe[\"exclude_subgroups\"])\n",
    "\n",
    "    if excl_subgroup_column is not None:\n",
    "        print(f\"Dropping values: {excl_subgroup_values}\")\n",
    "        keep_rows_mask = ~org_train[excl_subgroup_column].isin(excl_subgroup_values)\n",
    "\n",
    "    n_rows_to_drop = (~keep_rows_mask).sum()\n",
    "    if n_rows_to_drop > 0:\n",
    "        print(f\"Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows from {excl_subgroup_colname}\")\n",
    "        X_train = X_train[keep_rows_mask]\n",
    "        y_train = y_train[keep_rows_mask]\n",
    "        group_train = group_train[keep_rows_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd0e0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Fitting the Model\n",
    "\n",
    "Select which model to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcf50c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "if (universe[\"model\"] == \"logreg\"):\n",
    "    model = LogisticRegression()\n",
    "elif (universe[\"model\"] == \"rf\"):\n",
    "    model = RandomForestClassifier()\n",
    "elif (universe[\"model\"] == \"svm\"):\n",
    "    model = SVC()\n",
    "elif (universe[\"model\"] == \"gbm\"):\n",
    "    model = GradientBoostingClassifier()\n",
    "elif (universe[\"model\"] == \"elasticnet\"):\n",
    "    model = LogisticRegression(penalty = 'elasticnet', solver = 'saga', l1_ratio = 0.5)\n",
    "else:\n",
    "    raise \"Unsupported universe.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422ad17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fairness_multiverse.universe import predict_w_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f5b15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"continuous_processor\", continuous_processor),\n",
    "    (\"categorical_preprocessor\", categorical_preprocessor),\n",
    "    (\"scale\", StandardScaler() if universe[\"scale\"] == \"scale\" else None),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)\n",
    "y_pred_default = predict_w_threshold(y_prob, 0.5)\n",
    "\n",
    "# Naive prediction\n",
    "accuracy_score(y_true = y_true, y_pred = y_pred_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c72f79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea335dd0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## (Fairness) Metrics\n",
    "\n",
    "- Using [Fairlearn](https://fairlearn.org/v0.8/quickstart.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702fac8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "colname_to_bin = \"RAC1P\"\n",
    "majority_value = features_org[colname_to_bin].mode()[0]\n",
    "\n",
    "org_test[\"majmin\"] = np.where(org_test[colname_to_bin] == majority_value, \"majority\", \"minority\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "178072b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "The greater of two metrics: `true_positive_rate_difference` and\n",
    "`false_positive_rate_difference`. The former is the difference between the\n",
    "largest and smallest of $P[h(X)=1 | A=a, Y=1]$, across all values :math:`a`\n",
    "of the sensitive feature(s). The latter is defined similarly, but for\n",
    "$P[h(X)=1 | A=a, Y=0]$.\n",
    "The equalized odds difference of 0 means that all groups have the same\n",
    "true positive, true negative, false positive, and false negative rates. [src](https://fairlearn.org/main/api_reference/generated/fairlearn.metrics.equalized_odds_difference.html)\n",
    "\n",
    "> This shouldn't differ based on which class we see as \"good\" or \"bad\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e12cf4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_universe = universe.copy()\n",
    "example_universe[\"cutoff\"] = example_universe[\"cutoff\"][0]\n",
    "example_universe[\"eval_fairness_grouping\"] = example_universe[\"eval_fairness_grouping\"][0]\n",
    "fairness_dict, metric_frame = universe_analysis.compute_metrics(\n",
    "    example_universe,\n",
    "    y_pred_prob=y_prob,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb6da15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Overall\n",
    "\n",
    "#### Fairness\n",
    "\n",
    "Main fairness target: **Equalized Odds**.\n",
    "Seems to be a better fit than equal opportunity, since we're not only interested in Y = 1.\n",
    "Seems to be a better fit than demographic parity, since we also care about accuracy, not just equal distribution of preds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a335f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Pick column for computation of fairness metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d960396",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Performance\n",
    "\n",
    "Overall performance measures, most interesting in relation to the measures split by group below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95c9ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_frame.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e50eb0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### By Group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12122e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_frame.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408b097",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Graphical comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab86de",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In a graphic\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3df12f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Equality of opportunity violation\n",
    "\n",
    "```python\n",
    "white_tpr = np.mean(y_pred[(y_true == 1) & (group_test == 1)])\n",
    "black_tpr = np.mean(y_pred[(y_true == 1) & (group_test == 2)])\n",
    "\n",
    "white_tpr - black_tpr\n",
    "```\n",
    "\n",
    "## Final Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5790d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_universes = universe_analysis.generate_sub_universes()\n",
    "len(sub_universes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc62dbd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Uses excl_subgroup_column and values from the global scope\n",
    "\n",
    "def filter_sub_universe_data(sub_universe, org_test):\n",
    "  # Generate an all True mask to start with\n",
    "  keep_rows_mask = np.ones(org_test.shape[0], dtype=bool)\n",
    "\n",
    "  # Potentially remove any subgroups from the test set\n",
    "  if (sub_universe[\"eval_exclude_subgroups\"] == \"exclude-in-eval\"):\n",
    "    if excl_subgroup_column is not None:\n",
    "      assert excl_subgroup_values is not None\n",
    "\n",
    "      exclude_subgroup_eval_mask = ~org_test[excl_subgroup_column].isin(excl_subgroup_values)\n",
    "      keep_rows_mask = keep_rows_mask & exclude_subgroup_eval_mask\n",
    "\n",
    "      n_rows_to_drop = (~exclude_subgroup_eval_mask).sum()\n",
    "      print(f\"[drop subgroups] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows from {excl_subgroup_colname}\")\n",
    "  elif (sub_universe[\"eval_exclude_subgroups\"] == \"keep-in-eval\"):\n",
    "    pass\n",
    "  else:\n",
    "    raise \"Unsupported eval_exclude_subgroups\"\n",
    "\n",
    "  # Potentially use a smaller and more \"convenient\" subset of the data to do evalaution on\n",
    "  if (sub_universe[\"eval_on_subset\"] == \"full\"):\n",
    "    pass\n",
    "  else:\n",
    "    if sub_universe[\"eval_on_subset\"].startswith(\"locality\"):\n",
    "      # Filter based on locality / region\n",
    "      # Step 1: Decide which regions to keep\n",
    "      if (sub_universe[\"eval_on_subset\"] == \"locality-largest-only\"):\n",
    "        # Use the largest PUMA region\n",
    "        puma_regions_to_keep = [org_test[\"PUMA\"].value_counts().idxmax()]\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-whitest-only\"):\n",
    "        # Find the majority class on the prot. attribute\n",
    "        majority_class = org_test[\"RAC1P\"].value_counts().index[0]\n",
    "        majority_class\n",
    "\n",
    "        # Find the PUMA region with the highest share of the majority class\n",
    "        counts = pd.DataFrame()\n",
    "        counts[\"full\"] = org_test[\"PUMA\"].value_counts(sort=False)\n",
    "        counts[\"majority\"] = org_test[org_test[\"RAC1P\"] == majority_class][\"PUMA\"].value_counts(sort=False)\n",
    "        counts[\"fraction\"] = counts[\"majority\"] / counts[\"full\"]\n",
    "\n",
    "        # Use the PUMA region with the highest share of the majority class\n",
    "        majority_puma_id = counts.sort_values(by=\"fraction\", ascending=False).index[0]\n",
    "        puma_regions_to_keep = [majority_puma_id]\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-city-la\"):\n",
    "        puma_regions_to_keep = list(range(3701, 3769+1))\n",
    "      elif (sub_universe[\"eval_on_subset\"] == \"locality-city-sf\"):\n",
    "        puma_regions_to_keep = list(range(7501, 7507+1))\n",
    "\n",
    "      # Step 2: Keep only those regions\n",
    "      print(f\"Keeping the following PUMA regions: {puma_regions_to_keep}\")\n",
    "      eval_on_subset_mask = org_test[\"PUMA\"].isin(puma_regions_to_keep)\n",
    "    elif (sub_universe[\"eval_on_subset\"] == \"exclude-military\"):\n",
    "      # Only keep non-military personnel\n",
    "      eval_on_subset_mask = (org_test[\"MIL\"].isin([\"Never served in the military\", \"N/A (less than 17 years old)\"]))\n",
    "    elif (sub_universe[\"eval_on_subset\"] == \"exclude-non-citizens\"):\n",
    "      # Only keep US citizens\n",
    "      eval_on_subset_mask = ~(org_test[\"CIT\"] == \"Not a citizen of the U.S.\")\n",
    "    else:\n",
    "      raise \"Unsupported eval_on_subset\"\n",
    "\n",
    "    keep_rows_mask = keep_rows_mask & eval_on_subset_mask\n",
    "\n",
    "    n_rows_to_drop = (~eval_on_subset_mask).sum()\n",
    "    print(f\"[subset] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows\")\n",
    "\n",
    "  n_rows_to_drop = (~keep_rows_mask).sum()\n",
    "  print(f\"[TOTAL] Dropping N = {n_rows_to_drop} ({n_rows_to_drop / len(keep_rows_mask):.2%}) rows. Final size: {keep_rows_mask.sum()}.\")\n",
    "\n",
    "  return keep_rows_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6976413",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_output = universe_analysis.generate_final_output(\n",
    "    y_pred_prob=y_prob,\n",
    "    y_test=y_true,\n",
    "    org_test=org_test,\n",
    "    save=True,\n",
    "    filter_data=filter_sub_universe_data\n",
    ")\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb937e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairml-multiverse-J_lJSXon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.406852,
   "end_time": "2025-04-24T19:03:18.895614",
   "environment_variables": {},
   "exception": true,
   "input_path": "universe_analysis.ipynb",
   "output_path": "output/runs/2/notebooks/m_2-2d4dacc3da52d3763f77618153b1af95.ipynb",
   "parameters": {
    "output_dir": "output",
    "run_no": "2",
    "seed": "2023",
    "universe": "{\"cutoff\": [\"quantile_0.15\", \"quantile_0.3\"], \"exclude_features\": \"frau1\", \"model\": \"rf\"}",
    "universe_id": "2d4dacc3da52d3763f77618153b1af95"
   },
   "start_time": "2025-04-24T19:03:16.488762",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}