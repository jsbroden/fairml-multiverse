{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93721ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/julia/Desktop/Master_Thesis/Example_Code/Kern24_code\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/julia/Desktop/Master_Thesis/Example_Code/Kern24_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52565df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/julia/Desktop/Master_Thesis/Example_Code/Kern24_code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "os.makedirs(\"output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19601a27",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80862496",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'aif360[Reductions]'\n",
    "!pip install 'aif360[inFairness]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee7f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "from utils import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a507d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21120c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f = pd.read_csv(\"./output/X_train_f.csv\") # 2010 - 2015, w. protected attributes\n",
    "X_train_fs = pd.read_csv(\"./output/X_train_fs.csv\") # 2015, w. protected attributes\n",
    "X_train_s = pd.read_csv(\"./output/X_train_s.csv\") # 2010 - 2015, w/o protected attributes\n",
    "X_train_ss = pd.read_csv(\"./output/X_train_ss.csv\") # 2015, w/o protected attributes\n",
    "y_train = pd.read_csv(\"./output/y_train.csv\").iloc[:,0]\n",
    "y_train_s = pd.read_csv(\"./output/y_train_s.csv\").iloc[:,0]\n",
    "\n",
    "X_test_f = pd.read_csv(\"./output/X_test_f.csv\")\n",
    "X_test_s = pd.read_csv(\"./output/X_test_s.csv\")\n",
    "y_test = pd.read_csv(\"./output/y_test.csv\").iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb944d",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81f6ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f82   f132    0.019598\n",
       "f132  f82     0.019598\n",
       "f41   f51     0.020039\n",
       "f51   f41     0.020039\n",
       "f113  f116    0.020611\n",
       "f116  f113    0.020611\n",
       "f69   f77     0.021082\n",
       "f77   f69     0.021082\n",
       "f146  f8      0.021098\n",
       "f8    f146    0.021098\n",
       "f35   f31     0.021174\n",
       "f31   f35     0.021174\n",
       "f129  f28     0.021828\n",
       "f28   f129    0.021828\n",
       "f118  f17     0.022079\n",
       "f17   f118    0.022079\n",
       "f25   f21     0.024634\n",
       "f21   f25     0.024634\n",
       "f29   f19     0.026148\n",
       "f19   f29     0.026148\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computes the absolute value of the correlation matrix for the training features with protected attributes\n",
    "corrM = X_train_f.corr().abs() # Corr matrix of X\n",
    "corrM = corrM.unstack() # flatten\n",
    "corrMo = corrM.sort_values(kind = \"quicksort\") # sort correlations\n",
    "corrMo[corrMo < 1].tail(20) # Filters out the self-correlations (which equal 1) and prints the last 20 entries (lowest correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e920c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(5) # Create splits by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f653a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 4997 4998 4999] TEST: [5000 5001 5002 ... 9997 9998 9999]\n",
      "TRAIN: [   0    1    2 ... 9997 9998 9999] TEST: [10000 10001 10002 ... 14997 14998 14999]\n",
      "TRAIN: [    0     1     2 ... 14997 14998 14999] TEST: [15000 15001 15002 ... 19997 19998 19999]\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [20000 20001 20002 ... 24997 24998 24999]\n",
      "TRAIN: [    0     1     2 ... 24997 24998 24999] TEST: [25000 25001 25002 ... 29997 29998 29999]\n"
     ]
    }
   ],
   "source": [
    "# Loops over each fold generated by tscv.split(X_train_f) and prints the training and testing indices. This output helps verify that the cross-validation splitting is working as expected.\n",
    "for train_index, test_index in tscv.split(X_train_f):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197e186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the make_scorer function to wrap your custom functions precision_at_k and recall_at_k so they can be used in scikit-learn’s cross-validation and grid search.\n",
    "\n",
    "custom_precision25 = make_scorer(precision_at_k, needs_proba = True, k = 0.25) # Precision at top 25%\n",
    "custom_precision10 = make_scorer(precision_at_k, needs_proba = True, k = 0.10) # Precision at top 10%\n",
    "\n",
    "custom_recall25 = make_scorer(recall_at_k, needs_proba = True, k = 0.25) # Recall at top 25%\n",
    "custom_recall10 = make_scorer(recall_at_k, needs_proba = True, k = 0.10) # Recall at top 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d4a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates a dictionary named score mapping metric names to corresponding scoring \n",
    "functions or identifiers. This dictionary will be passed to cross-validation procedures \n",
    "so that multiple metrics are computed\n",
    "'''\n",
    "\n",
    "score = {'log_loss': 'neg_log_loss',\n",
    "         'auc': 'roc_auc',\n",
    "         'precision': 'precision',\n",
    "         'recall': 'recall',\n",
    "         'precision_at_k25': custom_precision25,\n",
    "         'recall_at_k25': custom_recall25,\n",
    "         'precision_at_k10': custom_precision10,\n",
    "         'recall_at_k10': custom_recall10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c38b96",
   "metadata": {},
   "source": [
    "## 01 Logit Regression (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216cd776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;none&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;none&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, penalty='none')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- A LogisticRegression model named glm1 is instantiated with no regularization \n",
    "using the lbfgs solver and with a maximum of 1000 iterations\n",
    "- The model is fitted on the training data that includes protected attributes\n",
    "'''\n",
    "glm1 = LogisticRegression(penalty = 'none', solver = 'lbfgs', max_iter = 1000)\n",
    "glm1.fit(X_train_f, y_train) # 2010 - 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db199fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/_functorch/deprecated.py:61: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- Performs cross-validation on the glm1 model using the pre-defined time series splits (tscv).\n",
    "- The scoring dictionary is passed so that all specified metrics are computed.\n",
    "- n_jobs=-1 indicates that the computation will use all available CPU cores.\n",
    "'''\n",
    "\n",
    "glmcv1 = cross_validate(estimator = glm1, \n",
    "                       X = X_train_f,\n",
    "                       y = y_train,\n",
    "                       cv = tscv,\n",
    "                       n_jobs = -1,\n",
    "                       scoring = score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db95e937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02775288, 0.07676315, 0.05511308, 0.10613513, 0.13099313]),\n",
       " 'score_time': array([0.0251472 , 0.028265  , 0.02342701, 0.02088761, 0.02689004]),\n",
       " 'test_log_loss': array([-0.45860281, -0.41509647, -0.40425142, -0.40786975, -0.38973944]),\n",
       " 'test_auc': array([0.56129034, 0.56794959, 0.57419967, 0.5926508 , 0.56986478]),\n",
       " 'test_precision': array([0.4, 0. , 0. , 0. , 0. ]),\n",
       " 'test_recall': array([0.00963855, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'test_precision_at_k25': array([0.19744205, 0.18944844, 0.186251  , 0.19904077, 0.17026379]),\n",
       " 'test_recall_at_k25': array([0.29759036, 0.32825485, 0.33285714, 0.34487535, 0.323217  ]),\n",
       " 'test_precision_at_k10': array([0.20359281, 0.18962076, 0.19560878, 0.21556886, 0.15968064]),\n",
       " 'test_recall_at_k10': array([0.12289157, 0.13157895, 0.14      , 0.14958449, 0.12139605])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displays the cross-validation results \n",
    "glmcv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4014d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "- Creates a DataFrame coefs1 to show the model coefficients.\n",
    "- Variable name and respective coefsicients\n",
    "'''\n",
    "\n",
    "coefs1 = pd.DataFrame(X_train_f.columns, columns = ['var'])\n",
    "coefs1['coef'] = pd.DataFrame(glm1.coef_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7e45f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glm1.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saves the trained logistic regression model glm1 to a file called glm1.joblib using joblib\n",
    "dump(glm1, 'glm1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fa04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['glm1b.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A second logistic regression model glm1b is instantiated and then fitted on the 2015-specific training data with protected attributes\n",
    "glm1b = LogisticRegression(penalty = 'none', solver = 'lbfgs', max_iter = 1000)\n",
    "glm1b.fit(X_train_fs, y_train_s) # 2015\n",
    "\n",
    "dump(glm1b, 'glm1b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759742",
   "metadata": {},
   "source": [
    "## 02 Logit Regression (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm2 = LogisticRegression(penalty = 'none', solver = 'lbfgs', max_iter = 1000)\n",
    "glm2.fit(X_train_s, y_train) # 2010 - 2015\n",
    "\n",
    "glmcv2 = cross_validate(estimator = glm1, \n",
    "                       X = X_train_s,\n",
    "                       y = y_train,\n",
    "                       cv = tscv,\n",
    "                       n_jobs = -1,\n",
    "                       scoring = score)\n",
    "\n",
    "glmcv2\n",
    "\n",
    "coefs2 = pd.DataFrame(X_train_s.columns, columns = ['var'])\n",
    "coefs2['coef'] = pd.DataFrame(glm2.coef_).transpose()\n",
    "\n",
    "dump(glm2, 'glm2.joblib')\n",
    "\n",
    "glm2b = LogisticRegression(penalty = 'none', solver = 'lbfgs', max_iter = 1000)\n",
    "glm2b.fit(X_train_ss, y_train_s) # 2015\n",
    "\n",
    "dump(glm2b, 'glm2b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c5f9d",
   "metadata": {},
   "source": [
    "## 01 Elastic Net (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'penalty': ['l1', 'l2'],\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'solver': ['liblinear']}\n",
    "\n",
    "netm1 = LogisticRegression()\n",
    "\n",
    "net1 = GridSearchCV(estimator = netm1, \n",
    "                   cv = tscv,\n",
    "                   param_grid = grid,\n",
    "                   n_jobs = -1, \n",
    "                   scoring = score,\n",
    "                   refit = 'auc',\n",
    "                   verbose = 2)\n",
    "net1.fit(X_train_f, y_train) \n",
    "\n",
    "pd.concat([pd.DataFrame(net1.cv_results_['params']), \n",
    "           pd.DataFrame(net1.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1)\n",
    "\n",
    "dump(net1, 'net1.joblib')\n",
    "\n",
    "net1b = LogisticRegression(**net1.best_params_)\n",
    "net1b.fit(X_train_fs, y_train_s) # 2015\n",
    "\n",
    "dump(net1b, 'net1b.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e330e9a7",
   "metadata": {},
   "source": [
    "## 02 Elastic Net (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "netm2 = LogisticRegression()\n",
    "\n",
    "net2 = GridSearchCV(estimator = netm2, \n",
    "                   cv = tscv,\n",
    "                   param_grid = grid,\n",
    "                   n_jobs = -1, \n",
    "                   scoring = score,\n",
    "                   refit = 'auc',\n",
    "                   verbose = 2)\n",
    "net2.fit(X_train_s, y_train) # 2010 - 2015\n",
    "\n",
    "pd.concat([pd.DataFrame(net2.cv_results_['params']), \n",
    "           pd.DataFrame(net2.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1)\n",
    "\n",
    "dump(net2, 'net2.joblib')\n",
    "\n",
    "net2b = LogisticRegression(**net2.best_params_)\n",
    "net2b.fit(X_train_ss, y_train_s) # 2015\n",
    "\n",
    "dump(net2b, 'net2b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a5ab6",
   "metadata": {},
   "source": [
    "## 01 Random Forest (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_estimators': [500, 750],\n",
    "        'min_samples_leaf': [1, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "rfm1 = RandomForestClassifier()\n",
    "\n",
    "rf1 = GridSearchCV(estimator = rfm1, \n",
    "                  cv = tscv,\n",
    "                  param_grid = grid,\n",
    "                  n_jobs = -1, \n",
    "                  scoring = score,\n",
    "                  refit = 'auc',\n",
    "                  verbose = 2)\n",
    "rf1.fit(X_train_f, y_train) # 2010 - 2015\n",
    "\n",
    "pd.concat([pd.DataFrame(rf1.cv_results_['params']), \n",
    "           pd.DataFrame(rf1.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1)\n",
    "\n",
    "dump(rf1, 'rf1.joblib')\n",
    "\n",
    "rf1b = RandomForestClassifier(**rf1.best_params_)\n",
    "rf1b.fit(X_train_fs, y_train_s) # 2015\n",
    "\n",
    "dump(rf1b, 'rf1b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734763a8",
   "metadata": {},
   "source": [
    "## 02 Random Forest (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d75d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm2 = RandomForestClassifier()\n",
    "\n",
    "rf2 = GridSearchCV(estimator = rfm2, \n",
    "                  cv = tscv,\n",
    "                  param_grid = grid,\n",
    "                  n_jobs = -1, \n",
    "                  scoring = score,\n",
    "                  refit = 'auc',\n",
    "                  verbose = 2)\n",
    "rf2.fit(X_train_s, y_train) # 2010 - 2015\n",
    "\n",
    "pd.concat([pd.DataFrame(rf2.cv_results_['params']), \n",
    "           pd.DataFrame(rf2.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1)\n",
    "\n",
    "dump(rf2, 'rf2.joblib')\n",
    "\n",
    "rf2b = RandomForestClassifier(**rf2.best_params_)\n",
    "rf2b.fit(X_train_ss, y_train_s) # 2015\n",
    "\n",
    "dump(rf2b, 'rf2b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e55d8b",
   "metadata": {},
   "source": [
    "## 01 Gradient Boosting (w. protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'learning_rate': [0.01, 0.025, 0.05],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'max_features': ['log2', 'sqrt'],\n",
    "        'subsample': [0.6, 0.8],\n",
    "        'n_estimators': [250, 500, 750]\n",
    "       }\n",
    "\n",
    "gb1 = GradientBoostingClassifier()\n",
    "\n",
    "gbm1 = GridSearchCV(estimator = gb1, \n",
    "                   cv = tscv,\n",
    "                   param_grid = grid,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = score,\n",
    "                   refit = 'auc',\n",
    "                   verbose = 2)\n",
    "gbm1.fit(X_train_f, y_train) # 2010 - 2015\n",
    "\n",
    "pd.concat([pd.DataFrame(gbm1.cv_results_['params']), \n",
    "           pd.DataFrame(gbm1.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1).tail(50)\n",
    "\n",
    "dump(gbm1, 'gbm1.joblib')\n",
    "\n",
    "gbm1b = GradientBoostingClassifier(**gbm1.best_params_)\n",
    "gbm1b.fit(X_train_fs, y_train_s) # 2015\n",
    "\n",
    "dump(gbm1b, 'gbm1b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f848cba",
   "metadata": {},
   "source": [
    "# 02 Gradient Boosting (w/o protected attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2 = GradientBoostingClassifier()\n",
    "\n",
    "gbm2 = GridSearchCV(estimator = gb2, \n",
    "                   cv = tscv,\n",
    "                   param_grid = grid,\n",
    "                   n_jobs = -1,\n",
    "                   scoring = score,\n",
    "                   refit = 'auc',\n",
    "                   verbose = 2)\n",
    "gbm2.fit(X_train_s, y_train) # 2010 - 2015\n",
    "\n",
    "pd.concat([pd.DataFrame(gbm2.cv_results_['params']), \n",
    "           pd.DataFrame(gbm2.cv_results_['mean_test_auc'], columns = ['roc_auc'])],\n",
    "           axis = 1).tail(50)\n",
    "\n",
    "dump(gbm2, 'gbm2.joblib')\n",
    "\n",
    "gbm2b = GradientBoostingClassifier(**gbm2.best_params_)\n",
    "gbm2b.fit(X_train_ss, y_train_s) # 2015\n",
    "\n",
    "dump(gbm2b, 'gbm2b.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8022f88",
   "metadata": {},
   "source": [
    "## Output CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353bb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit\n",
    "\n",
    "auc_glm1 = pd.DataFrame(glmcv1['test_auc']).transpose()\n",
    "auc_glm1 = auc_glm1.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "prec10_glm1 = pd.DataFrame(glmcv1['test_precision_at_k10']).transpose()\n",
    "prec10_glm1 = prec10_glm1.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "prec25_glm1 = pd.DataFrame(glmcv1['test_precision_at_k25']).transpose()\n",
    "prec25_glm1 = prec25_glm1.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "rec10_glm1 = pd.DataFrame(glmcv1['test_recall_at_k10']).transpose()\n",
    "rec10_glm1 = rec10_glm1.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "rec25_glm1 = pd.DataFrame(glmcv1['test_recall_at_k25']).transpose()\n",
    "rec25_glm1 = rec25_glm1.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "auc_glm2 = pd.DataFrame(glmcv2['test_auc']).transpose()\n",
    "auc_glm2 = auc_glm2.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "prec10_glm2 = pd.DataFrame(glmcv2['test_precision_at_k10']).transpose()\n",
    "prec10_glm2 = prec10_glm2.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "prec25_glm2 = pd.DataFrame(glmcv2['test_precision_at_k25']).transpose()\n",
    "prec25_glm2 = prec25_glm2.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "rec10_glm2 = pd.DataFrame(glmcv2['test_recall_at_k10']).transpose()\n",
    "rec10_glm2 = rec10_glm2.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n",
    "\n",
    "rec25_glm2 = pd.DataFrame(glmcv2['test_recall_at_k25']).transpose()\n",
    "rec25_glm2 = rec25_glm2.rename(columns={0: \"2011\", 1: \"2012\", 2: \"2013\", 3: \"2014\", 4: \"2015\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde98ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic net\n",
    "\n",
    "auc_net1 = pd.concat([pd.DataFrame(net1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                      pd.DataFrame(net1.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                      pd.DataFrame(net1.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                      pd.DataFrame(net1.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                      pd.DataFrame(net1.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                      pd.DataFrame(net1.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                     axis = 1)\n",
    "\n",
    "auc_best_net1 = auc_net1[auc_net1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_net1 = pd.concat([pd.DataFrame(net1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(net1.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                         pd.DataFrame(net1.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                         pd.DataFrame(net1.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                         pd.DataFrame(net1.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                         pd.DataFrame(net1.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec10_best_net1 = prec10_net1[prec10_net1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_net1 = pd.concat([pd.DataFrame(net1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(net1.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                         pd.DataFrame(net1.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                         pd.DataFrame(net1.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                         pd.DataFrame(net1.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                         pd.DataFrame(net1.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec25_best_net1 = prec25_net1[prec25_net1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_net1 = pd.concat([pd.DataFrame(net1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(net1.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(net1.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(net1.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(net1.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(net1.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec10_best_net1 = rec10_net1[rec10_net1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_net1 = pd.concat([pd.DataFrame(net1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(net1.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(net1.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(net1.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(net1.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(net1.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec25_best_net1 = rec25_net1[rec25_net1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "auc_net2 = pd.concat([pd.DataFrame(net2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                      pd.DataFrame(net2.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                      pd.DataFrame(net2.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                      pd.DataFrame(net2.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                      pd.DataFrame(net2.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                      pd.DataFrame(net2.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                     axis = 1)\n",
    "\n",
    "auc_best_net2 = auc_net2[auc_net2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_net2 = pd.concat([pd.DataFrame(net2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(net2.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                         pd.DataFrame(net2.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                         pd.DataFrame(net2.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                         pd.DataFrame(net2.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                         pd.DataFrame(net2.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec10_best_net2 = prec10_net2[prec10_net2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_net2 = pd.concat([pd.DataFrame(net2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(net2.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                         pd.DataFrame(net2.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                         pd.DataFrame(net2.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                         pd.DataFrame(net2.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                         pd.DataFrame(net2.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec25_best_net2 = prec25_net2[prec25_net2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_net2 = pd.concat([pd.DataFrame(net2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(net2.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(net2.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(net2.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(net2.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(net2.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec10_best_net2 = rec10_net2[rec10_net2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_net2 = pd.concat([pd.DataFrame(net2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(net2.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(net2.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(net2.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(net2.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(net2.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec25_best_net2 = rec25_net2[rec25_net2.ranks == 1].drop(columns = ['ranks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "\n",
    "auc_rf1 = pd.concat([pd.DataFrame(rf1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                     pd.DataFrame(rf1.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                     pd.DataFrame(rf1.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                     pd.DataFrame(rf1.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                     pd.DataFrame(rf1.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                     pd.DataFrame(rf1.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                    axis = 1)\n",
    "\n",
    "auc_best_rf1 = auc_rf1[auc_rf1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_rf1 = pd.concat([pd.DataFrame(rf1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(rf1.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "prec10_best_rf1 = prec10_rf1[prec10_rf1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_rf1 = pd.concat([pd.DataFrame(rf1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(rf1.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(rf1.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "prec25_best_rf1 = prec25_rf1[prec25_rf1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_rf1 = pd.concat([pd.DataFrame(rf1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                       pd.DataFrame(rf1.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                      axis = 1)\n",
    "\n",
    "rec10_best_rf1 = rec10_rf1[rec10_rf1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_rf1 = pd.concat([pd.DataFrame(rf1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                       pd.DataFrame(rf1.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                       pd.DataFrame(rf1.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                      axis = 1)\n",
    "\n",
    "rec25_best_rf1 = rec25_rf1[rec25_rf1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "auc_rf2 = pd.concat([pd.DataFrame(rf2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                     pd.DataFrame(rf2.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                     pd.DataFrame(rf2.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                     pd.DataFrame(rf2.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                     pd.DataFrame(rf2.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                     pd.DataFrame(rf2.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                    axis = 1)\n",
    "\n",
    "auc_best_rf2 = auc_rf2[auc_rf2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_rf2 = pd.concat([pd.DataFrame(rf2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(rf2.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "prec10_best_rf2 = prec10_rf2[prec10_rf2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_rf2 = pd.concat([pd.DataFrame(rf2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(rf2.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(rf2.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "prec25_best_rf2 = prec25_rf2[prec25_rf2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_rf2 = pd.concat([pd.DataFrame(rf2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                       pd.DataFrame(rf2.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                      axis = 1)\n",
    "\n",
    "rec10_best_rf2 = rec10_rf2[rec10_rf2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_rf2 = pd.concat([pd.DataFrame(rf2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                       pd.DataFrame(rf2.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                       pd.DataFrame(rf2.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                      axis = 1)\n",
    "\n",
    "rec25_best_rf2 = rec25_rf2[rec25_rf2.ranks == 1].drop(columns = ['ranks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd045dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM\n",
    "\n",
    "auc_gbm1 = pd.concat([pd.DataFrame(gbm1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                      pd.DataFrame(gbm1.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                      pd.DataFrame(gbm1.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                      pd.DataFrame(gbm1.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                      pd.DataFrame(gbm1.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                      pd.DataFrame(gbm1.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                     axis = 1)\n",
    "\n",
    "auc_best_gbm1 = auc_gbm1[auc_gbm1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_gbm1 = pd.concat([pd.DataFrame(gbm1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                         pd.DataFrame(gbm1.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec10_best_gbm1 = prec10_gbm1[prec10_gbm1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_gbm1 = pd.concat([pd.DataFrame(gbm1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                         pd.DataFrame(gbm1.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                         pd.DataFrame(gbm1.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec25_best_gbm1 = prec25_gbm1[prec25_gbm1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_gbm1 = pd.concat([pd.DataFrame(gbm1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(gbm1.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec10_best_gbm1 = rec10_gbm1[rec10_gbm1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_gbm1 = pd.concat([pd.DataFrame(gbm1.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(gbm1.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(gbm1.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec25_best_gbm1 = rec25_gbm1[rec25_gbm1.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "auc_gbm2 = pd.concat([pd.DataFrame(gbm2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                      pd.DataFrame(gbm2.cv_results_['split0_test_auc'], columns = ['2011']), \n",
    "                      pd.DataFrame(gbm2.cv_results_['split1_test_auc'], columns = ['2012']),\n",
    "                      pd.DataFrame(gbm2.cv_results_['split2_test_auc'], columns = ['2013']),\n",
    "                      pd.DataFrame(gbm2.cv_results_['split3_test_auc'], columns = ['2014']),\n",
    "                      pd.DataFrame(gbm2.cv_results_['split4_test_auc'], columns = ['2015'])],\n",
    "                     axis = 1)\n",
    "\n",
    "auc_best_gbm2 = auc_gbm2[auc_gbm2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec10_gbm2 = pd.concat([pd.DataFrame(gbm2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split0_test_precision_at_k10'], columns = ['2011']), \n",
    "                         pd.DataFrame(gbm2.cv_results_['split1_test_precision_at_k10'], columns = ['2012']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split2_test_precision_at_k10'], columns = ['2013']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split3_test_precision_at_k10'], columns = ['2014']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split4_test_precision_at_k10'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec10_best_gbm2 = prec10_gbm2[prec10_gbm2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "prec25_gbm2 = pd.concat([pd.DataFrame(gbm2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split0_test_precision_at_k25'], columns = ['2011']), \n",
    "                         pd.DataFrame(gbm2.cv_results_['split1_test_precision_at_k25'], columns = ['2012']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split2_test_precision_at_k25'], columns = ['2013']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split3_test_precision_at_k25'], columns = ['2014']),\n",
    "                         pd.DataFrame(gbm2.cv_results_['split4_test_precision_at_k25'], columns = ['2015'])],\n",
    "                        axis = 1)\n",
    "\n",
    "prec25_best_gbm2 = prec25_gbm2[prec25_gbm2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec10_gbm2 = pd.concat([pd.DataFrame(gbm2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split0_test_recall_at_k10'], columns = ['2011']), \n",
    "                        pd.DataFrame(gbm2.cv_results_['split1_test_recall_at_k10'], columns = ['2012']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split2_test_recall_at_k10'], columns = ['2013']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split3_test_recall_at_k10'], columns = ['2014']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split4_test_recall_at_k10'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec10_best_gbm2 = rec10_gbm2[rec10_gbm2.ranks == 1].drop(columns = ['ranks'])\n",
    "\n",
    "rec25_gbm2 = pd.concat([pd.DataFrame(gbm2.cv_results_['rank_test_auc'], columns = ['ranks']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split0_test_recall_at_k25'], columns = ['2011']), \n",
    "                        pd.DataFrame(gbm2.cv_results_['split1_test_recall_at_k25'], columns = ['2012']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split2_test_recall_at_k25'], columns = ['2013']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split3_test_recall_at_k25'], columns = ['2014']),\n",
    "                        pd.DataFrame(gbm2.cv_results_['split4_test_recall_at_k25'], columns = ['2015'])],\n",
    "                       axis = 1)\n",
    "\n",
    "rec25_best_gbm2 = rec25_gbm2[rec25_gbm2.ranks == 1].drop(columns = ['ranks'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7594f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "\n",
    "aucs1 = pd.concat([auc_glm1,\n",
    "                   auc_best_net1,\n",
    "                   auc_best_rf1,\n",
    "                   auc_best_gbm1],\n",
    "                  axis = 0)\n",
    "\n",
    "aucs1.to_latex('./output/train_cv_auc1.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "precs1_10 = pd.concat([prec10_glm1,\n",
    "                       prec10_best_net1,\n",
    "                       prec10_best_rf1,\n",
    "                       prec10_best_gbm1],\n",
    "                      axis = 0)\n",
    "\n",
    "precs1_10.to_latex('./output/train_cv_prec1_10.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "precs1_25 = pd.concat([prec25_glm1,\n",
    "                       prec25_best_net1,\n",
    "                       prec25_best_rf1,\n",
    "                       prec25_best_gbm1],\n",
    "                      axis = 0)\n",
    "\n",
    "precs1_25.to_latex('./output/train_cv_prec1_25.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "recs1_10 = pd.concat([rec10_glm1,\n",
    "                      rec10_best_net1,\n",
    "                      rec10_best_rf1,\n",
    "                      rec10_best_gbm1],\n",
    "                     axis = 0)\n",
    "\n",
    "recs1_10.to_latex('./output/train_cv_rec1_10.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "recs1_25 = pd.concat([rec25_glm1,\n",
    "                      rec25_best_net1,\n",
    "                      rec25_best_rf1,\n",
    "                      rec25_best_gbm1],\n",
    "                     axis = 0)\n",
    "\n",
    "recs1_25.to_latex('./output/train_cv_rec1_25.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "aucs2 = pd.concat([auc_glm2,\n",
    "                   auc_best_net2,\n",
    "                   auc_best_rf2,\n",
    "                   auc_best_gbm2],\n",
    "                  axis = 0)\n",
    "\n",
    "aucs2.to_latex('./output/train_cv_auc2.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "precs2_10 = pd.concat([prec10_glm2,\n",
    "                       prec10_best_net2,\n",
    "                       prec10_best_rf2,\n",
    "                       prec10_best_gbm2],\n",
    "                     axis = 0)\n",
    "\n",
    "precs2_10.to_latex('./output/train_cv_prec2_10.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "precs2_25 = pd.concat([prec25_glm2,\n",
    "                       prec25_best_net2,\n",
    "                       prec25_best_rf2,\n",
    "                       prec25_best_gbm2],\n",
    "                     axis = 0)\n",
    "\n",
    "precs2_25.to_latex('./output/train_cv_prec2_25.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "recs2_10 = pd.concat([rec10_glm2,\n",
    "                      rec10_best_net2,\n",
    "                      rec10_best_rf2,\n",
    "                      rec10_best_gbm2],\n",
    "                     axis = 0)\n",
    "\n",
    "recs2_10.to_latex('./output/train_cv_rec2_10.tex', index = False, float_format = \"%.3f\")\n",
    "\n",
    "recs2_25 = pd.concat([rec25_glm2,\n",
    "                      rec25_best_net2,\n",
    "                      rec25_best_rf2,\n",
    "                      rec25_best_gbm2],\n",
    "                     axis = 0)\n",
    "\n",
    "recs2_25.to_latex('./output/train_cv_rec2_25.tex', index = False, float_format = \"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83452516",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines percentage thresholds that will later be used to decide cutoff values for converting probability scores into class predictions.\n",
    "k75 = 0.75 # Top 75% \n",
    "k25 = 0.25 # Top 25% \n",
    "k10 = 0.1 # Top 10% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit\n",
    "\n",
    "# Predicts probabilities on test data\n",
    "glm1_p = glm1.predict_proba(X_test_f)[:,1] # glm1\n",
    "\n",
    "# Determines thresholds by sorting the probabilities in descending order\n",
    "threshold75 = np.sort(glm1_p)[::-1][int(k75*len(glm1_p))]\n",
    "threshold25 = np.sort(glm1_p)[::-1][int(k25*len(glm1_p))]\n",
    "threshold10 = np.sort(glm1_p)[::-1][int(k10*len(glm1_p))]\n",
    "\n",
    "# Creates binary predictions based on these thresholds\n",
    "glm1_c1 = glm1_p.copy()\n",
    "glm1_c1[glm1_c1 < threshold10] = 0\n",
    "glm1_c1[glm1_c1 >= threshold10] = 1\n",
    "\n",
    "# glm1_c2 uses the threshold25\n",
    "glm1_c2 = glm1_p.copy()\n",
    "glm1_c2[glm1_c2 < threshold25] = 0\n",
    "glm1_c2[glm1_c2 >= threshold25] = 1\n",
    "\n",
    "# glm1_c3 uses both threshold75 and threshold25\n",
    "glm1_c3 = glm1_p.copy()\n",
    "glm1_c3[(glm1_c3 <= threshold75) | (glm1_c3 >= threshold25)] = 0\n",
    "glm1_c3[(glm1_c3 > threshold75) & (glm1_c3 < threshold25)] = 1\n",
    "\n",
    "# The same prediction, thresholding, and binary conversion process is repeated for each model variant\n",
    "glm1b_p = glm1b.predict_proba(X_test_f)[:,1] # glm1b\n",
    "\n",
    "threshold75 = np.sort(glm1b_p)[::-1][int(k75*len(glm1b_p))]\n",
    "threshold25 = np.sort(glm1b_p)[::-1][int(k25*len(glm1b_p))]\n",
    "threshold10 = np.sort(glm1b_p)[::-1][int(k10*len(glm1b_p))]\n",
    "\n",
    "glm1b_c1 = glm1b_p.copy()\n",
    "glm1b_c1[glm1b_c1 < threshold10] = 0\n",
    "glm1b_c1[glm1b_c1 >= threshold10] = 1\n",
    "\n",
    "glm1b_c2 = glm1b_p.copy()\n",
    "glm1b_c2[glm1b_c2 < threshold25] = 0\n",
    "glm1b_c2[glm1b_c2 >= threshold25] = 1\n",
    "\n",
    "glm1b_c3 = glm1b_p.copy()\n",
    "glm1b_c3[(glm1b_c3 <= threshold75) | (glm1b_c3 >= threshold25)] = 0\n",
    "glm1b_c3[(glm1b_c3 > threshold75) & (glm1b_c3 < threshold25)] = 1\n",
    "\n",
    "glm2_p = glm2.predict_proba(X_test_s)[:,1] # glm2\n",
    "\n",
    "threshold75 = np.sort(glm2_p)[::-1][int(k75*len(glm2_p))]\n",
    "threshold25 = np.sort(glm2_p)[::-1][int(k25*len(glm2_p))]\n",
    "threshold10 = np.sort(glm2_p)[::-1][int(k10*len(glm2_p))]\n",
    "\n",
    "glm2_c1 = glm2_p.copy()\n",
    "glm2_c1[glm2_c1 < threshold10] = 0\n",
    "glm2_c1[glm2_c1 >= threshold10] = 1\n",
    "\n",
    "glm2_c2 = glm2_p.copy()\n",
    "glm2_c2[glm2_c2 < threshold25] = 0\n",
    "glm2_c2[glm2_c2 >= threshold25] = 1\n",
    "\n",
    "glm2_c3 = glm2_p.copy()\n",
    "glm2_c3[(glm2_c3 <= threshold75) | (glm2_c3 >= threshold25)] = 0\n",
    "glm2_c3[(glm2_c3 > threshold75) & (glm2_c3 < threshold25)] = 1\n",
    "\n",
    "glm2b_p = glm2b.predict_proba(X_test_s)[:,1] # glm2b\n",
    "\n",
    "threshold75 = np.sort(glm2b_p)[::-1][int(k75*len(glm2b_p))]\n",
    "threshold25 = np.sort(glm2b_p)[::-1][int(k25*len(glm2b_p))]\n",
    "threshold10 = np.sort(glm2b_p)[::-1][int(k10*len(glm2b_p))]\n",
    "\n",
    "glm2b_c1 = glm2b_p.copy()\n",
    "glm2b_c1[glm2b_c1 < threshold10] = 0\n",
    "glm2b_c1[glm2b_c1 >= threshold10] = 1\n",
    "\n",
    "glm2b_c2 = glm2b_p.copy()\n",
    "glm2b_c2[glm2b_c2 < threshold25] = 0\n",
    "glm2b_c2[glm2b_c2 >= threshold25] = 1\n",
    "\n",
    "glm2b_c3 = glm2b_p.copy()\n",
    "glm2b_c3[(glm2b_c3 <= threshold75) | (glm2b_c3 >= threshold25)] = 0\n",
    "glm2b_c3[(glm2b_c3 > threshold75) & (glm2b_c3 < threshold25)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acd653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic net\n",
    "\n",
    "net1_p = net1.predict_proba(X_test_f)[:,1] # net1\n",
    "\n",
    "threshold75 = np.sort(net1_p)[::-1][int(k75*len(net1_p))]\n",
    "threshold25 = np.sort(net1_p)[::-1][int(k25*len(net1_p))]\n",
    "threshold10 = np.sort(net1_p)[::-1][int(k10*len(net1_p))]\n",
    "\n",
    "net1_c1 = net1_p.copy()\n",
    "net1_c1[net1_c1 < threshold10] = 0\n",
    "net1_c1[net1_c1 >= threshold10] = 1\n",
    "\n",
    "net1_c2 = net1_p.copy()\n",
    "net1_c2[net1_c2 < threshold25] = 0\n",
    "net1_c2[net1_c2 >= threshold25] = 1\n",
    "\n",
    "net1_c3 = net1_p.copy()\n",
    "net1_c3[(net1_c3 <= threshold75) | (net1_c3 >= threshold25)] = 0\n",
    "net1_c3[(net1_c3 > threshold75) & (net1_c3 < threshold25)] = 1\n",
    "\n",
    "net1b_p = net1b.predict_proba(X_test_f)[:,1] # net1b\n",
    "\n",
    "threshold75 = np.sort(net1b_p)[::-1][int(k75*len(net1b_p))]\n",
    "threshold25 = np.sort(net1b_p)[::-1][int(k25*len(net1b_p))]\n",
    "threshold10 = np.sort(net1b_p)[::-1][int(k10*len(net1b_p))]\n",
    "\n",
    "net1b_c1 = net1b_p.copy()\n",
    "net1b_c1[net1b_c1 < threshold10] = 0\n",
    "net1b_c1[net1b_c1 >= threshold10] = 1\n",
    "\n",
    "net1b_c2 = net1b_p.copy()\n",
    "net1b_c2[net1b_c2 < threshold25] = 0\n",
    "net1b_c2[net1b_c2 >= threshold25] = 1\n",
    "\n",
    "net1b_c3 = net1b_p.copy()\n",
    "net1b_c3[(net1b_c3 <= threshold75) | (net1b_c3 >= threshold25)] = 0\n",
    "net1b_c3[(net1b_c3 > threshold75) & (net1b_c3 < threshold25)] = 1\n",
    "\n",
    "net2_p = net2.predict_proba(X_test_s)[:,1] # net2\n",
    "\n",
    "threshold75 = np.sort(net2_p)[::-1][int(k75*len(net2_p))]\n",
    "threshold25 = np.sort(net2_p)[::-1][int(k25*len(net2_p))]\n",
    "threshold10 = np.sort(net2_p)[::-1][int(k10*len(net2_p))]\n",
    "\n",
    "net2_c1 = net2_p.copy()\n",
    "net2_c1[net2_c1 < threshold10] = 0\n",
    "net2_c1[net2_c1 >= threshold10] = 1\n",
    "\n",
    "net2_c2 = net2_p.copy()\n",
    "net2_c2[net2_c2 < threshold25] = 0\n",
    "net2_c2[net2_c2 >= threshold25] = 1\n",
    "\n",
    "net2_c3 = net2_p.copy()\n",
    "net2_c3[(net2_c3 <= threshold75) | (net2_c3 >= threshold25)] = 0\n",
    "net2_c3[(net2_c3 > threshold75) & (net2_c3 < threshold25)] = 1\n",
    "\n",
    "net2b_p = net2b.predict_proba(X_test_s)[:,1] # net2b\n",
    "\n",
    "threshold75 = np.sort(net2b_p)[::-1][int(k75*len(net2b_p))]\n",
    "threshold25 = np.sort(net2b_p)[::-1][int(k25*len(net2b_p))]\n",
    "threshold10 = np.sort(net2b_p)[::-1][int(k10*len(net2b_p))]\n",
    "\n",
    "net2b_c1 = net2b_p.copy()\n",
    "net2b_c1[net2b_c1 < threshold10] = 0\n",
    "net2b_c1[net2b_c1 >= threshold10] = 1\n",
    "\n",
    "net2b_c2 = net2b_p.copy()\n",
    "net2b_c2[net2b_c2 < threshold25] = 0\n",
    "net2b_c2[net2b_c2 >= threshold25] = 1\n",
    "\n",
    "net2b_c3 = net2b_p.copy()\n",
    "net2b_c3[(net2b_c3 <= threshold75) | (net2b_c3 >= threshold25)] = 0\n",
    "net2b_c3[(net2b_c3 > threshold75) & (net2b_c3 < threshold25)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "\n",
    "rf1_p = rf1.predict_proba(X_test_f)[:,1] # rf1\n",
    "\n",
    "threshold75 = np.sort(rf1_p)[::-1][int(k75*len(rf1_p))]\n",
    "threshold25 = np.sort(rf1_p)[::-1][int(k25*len(rf1_p))]\n",
    "threshold10 = np.sort(rf1_p)[::-1][int(k10*len(rf1_p))]\n",
    "\n",
    "rf1_c1 = rf1_p.copy()\n",
    "rf1_c1[rf1_c1 < threshold10] = 0\n",
    "rf1_c1[rf1_c1 >= threshold10] = 1\n",
    "\n",
    "rf1_c2 = rf1_p.copy()\n",
    "rf1_c2[rf1_c2 < threshold25] = 0\n",
    "rf1_c2[rf1_c2 >= threshold25] = 1\n",
    "\n",
    "rf1_c3 = rf1_p.copy()\n",
    "rf1_c3[(rf1_c3 <= threshold75) | (rf1_c3 >= threshold25)] = 0\n",
    "rf1_c3[(rf1_c3 > threshold75) & (rf1_c3 < threshold25)] = 1\n",
    "\n",
    "rf1b_p = rf1b.predict_proba(X_test_f)[:,1] # rf1b\n",
    "\n",
    "threshold75 = np.sort(rf1b_p)[::-1][int(k75*len(rf1b_p))]\n",
    "threshold25 = np.sort(rf1b_p)[::-1][int(k25*len(rf1b_p))]\n",
    "threshold10 = np.sort(rf1b_p)[::-1][int(k10*len(rf1b_p))]\n",
    "\n",
    "rf1b_c1 = rf1b_p.copy()\n",
    "rf1b_c1[rf1b_c1 < threshold10] = 0\n",
    "rf1b_c1[rf1b_c1 >= threshold10] = 1\n",
    "\n",
    "rf1b_c2 = rf1b_p.copy()\n",
    "rf1b_c2[rf1b_c2 < threshold25] = 0\n",
    "rf1b_c2[rf1b_c2 >= threshold25] = 1\n",
    "\n",
    "rf1b_c3 = rf1b_p.copy()\n",
    "rf1b_c3[(rf1b_c3 <= threshold75) | (rf1b_c3 >= threshold25)] = 0\n",
    "rf1b_c3[(rf1b_c3 > threshold75) & (rf1b_c3 < threshold25)] = 1\n",
    "\n",
    "rf2_p = rf2.predict_proba(X_test_s)[:,1] # rf2\n",
    "\n",
    "threshold75 = np.sort(rf2_p)[::-1][int(k75*len(rf2_p))]\n",
    "threshold25 = np.sort(rf2_p)[::-1][int(k25*len(rf2_p))]\n",
    "threshold10 = np.sort(rf2_p)[::-1][int(k10*len(rf2_p))]\n",
    "\n",
    "rf2_c1 = rf2_p.copy()\n",
    "rf2_c1[rf2_c1 < threshold10] = 0\n",
    "rf2_c1[rf2_c1 >= threshold10] = 1\n",
    "\n",
    "rf2_c2 = rf2_p.copy()\n",
    "rf2_c2[rf2_c2 < threshold25] = 0\n",
    "rf2_c2[rf2_c2 >= threshold25] = 1\n",
    "\n",
    "rf2_c3 = rf2_p.copy()\n",
    "rf2_c3[(rf2_c3 <= threshold75) | (rf2_c3 >= threshold25)] = 0\n",
    "rf2_c3[(rf2_c3 > threshold75) & (rf2_c3 < threshold25)] = 1\n",
    "\n",
    "rf2b_p = rf2b.predict_proba(X_test_s)[:,1] # rf2b\n",
    "\n",
    "threshold75 = np.sort(rf2b_p)[::-1][int(k75*len(rf2b_p))]\n",
    "threshold25 = np.sort(rf2b_p)[::-1][int(k25*len(rf2b_p))]\n",
    "threshold10 = np.sort(rf2b_p)[::-1][int(k10*len(rf2b_p))]\n",
    "\n",
    "rf2b_c1 = rf2b_p.copy()\n",
    "rf2b_c1[rf2b_c1 < threshold10] = 0\n",
    "rf2b_c1[rf2b_c1 >= threshold10] = 1\n",
    "\n",
    "rf2b_c2 = rf2b_p.copy()\n",
    "rf2b_c2[rf2b_c2 < threshold25] = 0\n",
    "rf2b_c2[rf2b_c2 >= threshold25] = 1\n",
    "\n",
    "rf2b_c3 = rf2b_p.copy()\n",
    "rf2b_c3[(rf2b_c3 <= threshold75) | (rf2b_c3 >= threshold25)] = 0\n",
    "rf2b_c3[(rf2b_c3 > threshold75) & (rf2b_c3 < threshold25)] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM\n",
    "\n",
    "gbm1_p = gbm1.predict_proba(X_test_f)[:,1] # gbm1\n",
    "\n",
    "threshold75 = np.sort(gbm1_p)[::-1][int(k75*len(gbm1_p))]\n",
    "threshold25 = np.sort(gbm1_p)[::-1][int(k25*len(gbm1_p))]\n",
    "threshold10 = np.sort(gbm1_p)[::-1][int(k10*len(gbm1_p))]\n",
    "\n",
    "gbm1_c1 = gbm1_p.copy()\n",
    "gbm1_c1[gbm1_c1 < threshold10] = 0\n",
    "gbm1_c1[gbm1_c1 >= threshold10] = 1\n",
    "\n",
    "gbm1_c2 = gbm1_p.copy()\n",
    "gbm1_c2[gbm1_c2 < threshold25] = 0\n",
    "gbm1_c2[gbm1_c2 >= threshold25] = 1\n",
    "\n",
    "gbm1_c3 = gbm1_p.copy()\n",
    "gbm1_c3[(gbm1_c3 <= threshold75) | (gbm1_c3 >= threshold25)] = 0\n",
    "gbm1_c3[(gbm1_c3 > threshold75) & (gbm1_c3 < threshold25)] = 1\n",
    "\n",
    "gbm1b_p = gbm1b.predict_proba(X_test_f)[:,1] # gbm1b\n",
    "\n",
    "threshold75 = np.sort(gbm1b_p)[::-1][int(k75*len(gbm1b_p))]\n",
    "threshold25 = np.sort(gbm1b_p)[::-1][int(k25*len(gbm1b_p))]\n",
    "threshold10 = np.sort(gbm1b_p)[::-1][int(k10*len(gbm1b_p))]\n",
    "\n",
    "gbm1b_c1 = gbm1b_p.copy()\n",
    "gbm1b_c1[gbm1b_c1 < threshold10] = 0\n",
    "gbm1b_c1[gbm1b_c1 >= threshold10] = 1\n",
    "\n",
    "gbm1b_c2 = gbm1b_p.copy()\n",
    "gbm1b_c2[gbm1b_c2 < threshold25] = 0\n",
    "gbm1b_c2[gbm1b_c2 >= threshold25] = 1\n",
    "\n",
    "gbm1b_c3 = gbm1b_p.copy()\n",
    "gbm1b_c3[(gbm1b_c3 <= threshold75) | (gbm1b_c3 >= threshold25)] = 0\n",
    "gbm1b_c3[(gbm1b_c3 > threshold75) & (gbm1b_c3 < threshold25)] = 1\n",
    "\n",
    "gbm2_p = gbm2.predict_proba(X_test_s)[:,1] # gbm2\n",
    "\n",
    "threshold75 = np.sort(gbm2_p)[::-1][int(k75*len(gbm2_p))]\n",
    "threshold25 = np.sort(gbm2_p)[::-1][int(k25*len(gbm2_p))]\n",
    "threshold10 = np.sort(gbm2_p)[::-1][int(k10*len(gbm2_p))]\n",
    "\n",
    "gbm2_c1 = gbm2_p.copy()\n",
    "gbm2_c1[gbm2_c1 < threshold10] = 0\n",
    "gbm2_c1[gbm2_c1 >= threshold10] = 1\n",
    "\n",
    "gbm2_c2 = gbm2_p.copy()\n",
    "gbm2_c2[gbm2_c2 < threshold25] = 0\n",
    "gbm2_c2[gbm2_c2 >= threshold25] = 1\n",
    "\n",
    "gbm2_c3 = gbm2_p.copy()\n",
    "gbm2_c3[(gbm2_c3 <= threshold75) | (gbm2_c3 >= threshold25)] = 0\n",
    "gbm2_c3[(gbm2_c3 > threshold75) & (gbm2_c3 < threshold25)] = 1\n",
    "\n",
    "gbm2b_p = gbm2b.predict_proba(X_test_s)[:,1] # gbm2b\n",
    "\n",
    "threshold75 = np.sort(gbm2b_p)[::-1][int(k75*len(gbm2b_p))]\n",
    "threshold25 = np.sort(gbm2b_p)[::-1][int(k25*len(gbm2b_p))]\n",
    "threshold10 = np.sort(gbm2b_p)[::-1][int(k10*len(gbm2b_p))]\n",
    "\n",
    "gbm2b_c1 = gbm2b_p.copy()\n",
    "gbm2b_c1[gbm2b_c1 < threshold10] = 0\n",
    "gbm2b_c1[gbm2b_c1 >= threshold10] = 1\n",
    "\n",
    "gbm2b_c2 = gbm2b_p.copy()\n",
    "gbm2b_c2[gbm2b_c2 < threshold25] = 0\n",
    "gbm2b_c2[gbm2b_c2 >= threshold25] = 1\n",
    "\n",
    "gbm2b_c3 = gbm2b_p.copy()\n",
    "gbm2b_c3[(gbm2b_c3 <= threshold75) | (gbm2b_c3 >= threshold25)] = 0\n",
    "gbm2b_c3[(gbm2b_c3 > threshold75) & (gbm2b_c3 < threshold25)] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4de84d",
   "metadata": {},
   "source": [
    "## Combine and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a381e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "- All the true labels (y_test) and prediction outputs (both probability estimates and binary conversion versions from each model) are concatenated horizontally into a single DataFrame preds_test.\n",
    "- This DataFrame is then saved as “preds_test.csv” in the “output” folde\n",
    "'''\n",
    "\n",
    "preds_test = pd.concat([pd.DataFrame(np.array(y_test), columns = ['y_test']),\n",
    "                         pd.DataFrame(glm1_p, columns = ['glm1_p']),\n",
    "                         pd.DataFrame(glm1_c1, columns = ['glm1_c1']),\n",
    "                         pd.DataFrame(glm1_c2, columns = ['glm1_c2']),\n",
    "                         pd.DataFrame(glm1_c3, columns = ['glm1_c3']),\n",
    "                         pd.DataFrame(glm1b_p, columns = ['glm1b_p']),\n",
    "                         pd.DataFrame(glm1b_c1, columns = ['glm1b_c1']),\n",
    "                         pd.DataFrame(glm1b_c2, columns = ['glm1b_c2']),\n",
    "                         pd.DataFrame(glm1b_c3, columns = ['glm1b_c3']),\n",
    "                         pd.DataFrame(glm2_p, columns = ['glm2_p']),\n",
    "                         pd.DataFrame(glm2_c1, columns = ['glm2_c1']),\n",
    "                         pd.DataFrame(glm2_c2, columns = ['glm2_c2']),\n",
    "                         pd.DataFrame(glm2_c3, columns = ['glm2_c3']),\n",
    "                         pd.DataFrame(glm2b_p, columns = ['glm2b_p']),\n",
    "                         pd.DataFrame(glm2b_c1, columns = ['glm2b_c1']),\n",
    "                         pd.DataFrame(glm2b_c2, columns = ['glm2b_c2']),\n",
    "                         pd.DataFrame(glm2b_c3, columns = ['glm2b_c3']),\n",
    "                         pd.DataFrame(net1_p, columns = ['net1_p']),\n",
    "                         pd.DataFrame(net1_c1, columns = ['net1_c1']),\n",
    "                         pd.DataFrame(net1_c2, columns = ['net1_c2']),\n",
    "                         pd.DataFrame(net1_c3, columns = ['net1_c3']),\n",
    "                         pd.DataFrame(net1b_p, columns = ['net1b_p']),\n",
    "                         pd.DataFrame(net1b_c1, columns = ['net1b_c1']),\n",
    "                         pd.DataFrame(net1b_c2, columns = ['net1b_c2']),\n",
    "                         pd.DataFrame(net1b_c3, columns = ['net1b_c3']),\n",
    "                         pd.DataFrame(net2_p, columns = ['net2_p']),\n",
    "                         pd.DataFrame(net2_c1, columns = ['net2_c1']),\n",
    "                         pd.DataFrame(net2_c2, columns = ['net2_c2']),\n",
    "                         pd.DataFrame(net2_c3, columns = ['net2_c3']),\n",
    "                         pd.DataFrame(net2b_p, columns = ['net2b_p']),\n",
    "                         pd.DataFrame(net2b_c1, columns = ['net2b_c1']),\n",
    "                         pd.DataFrame(net2b_c2, columns = ['net2b_c2']),\n",
    "                         pd.DataFrame(net2b_c3, columns = ['net2b_c3']),\n",
    "                         pd.DataFrame(rf1_p, columns = ['rf1_p']),\n",
    "                         pd.DataFrame(rf1_c1, columns = ['rf1_c1']),\n",
    "                         pd.DataFrame(rf1_c2, columns = ['rf1_c2']),\n",
    "                         pd.DataFrame(rf1_c3, columns = ['rf1_c3']),\n",
    "                         pd.DataFrame(rf1b_p, columns = ['rf1b_p']),\n",
    "                         pd.DataFrame(rf1b_c1, columns = ['rf1b_c1']),\n",
    "                         pd.DataFrame(rf1b_c2, columns = ['rf1b_c2']),\n",
    "                         pd.DataFrame(rf1b_c3, columns = ['rf1b_c3']),\n",
    "                         pd.DataFrame(rf2_p, columns = ['rf2_p']),\n",
    "                         pd.DataFrame(rf2_c1, columns = ['rf2_c1']),\n",
    "                         pd.DataFrame(rf2_c2, columns = ['rf2_c2']),\n",
    "                         pd.DataFrame(rf2_c3, columns = ['rf2_c3']),\n",
    "                         pd.DataFrame(rf2b_p, columns = ['rf2b_p']),\n",
    "                         pd.DataFrame(rf2b_c1, columns = ['rf2b_c1']),\n",
    "                         pd.DataFrame(rf2b_c2, columns = ['rf2b_c2']),\n",
    "                         pd.DataFrame(rf2b_c3, columns = ['rf2b_c3']),\n",
    "                         pd.DataFrame(gbm1_p, columns = ['gbm1_p']),\n",
    "                         pd.DataFrame(gbm1_c1, columns = ['gbm1_c1']),\n",
    "                         pd.DataFrame(gbm1_c2, columns = ['gbm1_c2']),\n",
    "                         pd.DataFrame(gbm1_c3, columns = ['gbm1_c3']),\n",
    "                         pd.DataFrame(gbm1b_p, columns = ['gbm1b_p']),\n",
    "                         pd.DataFrame(gbm1b_c1, columns = ['gbm1b_c1']),\n",
    "                         pd.DataFrame(gbm1b_c2, columns = ['gbm1b_c2']),\n",
    "                         pd.DataFrame(gbm1b_c3, columns = ['gbm1b_c3']),\n",
    "                         pd.DataFrame(gbm2_p, columns = ['gbm2_p']),\n",
    "                         pd.DataFrame(gbm2_c1, columns = ['gbm2_c1']),\n",
    "                         pd.DataFrame(gbm2_c2, columns = ['gbm2_c2']),\n",
    "                         pd.DataFrame(gbm2_c3, columns = ['gbm2_c3']),\n",
    "                         pd.DataFrame(gbm2b_p, columns = ['gbm2b_p']),\n",
    "                         pd.DataFrame(gbm2b_c1, columns = ['gbm2b_c1']),\n",
    "                         pd.DataFrame(gbm2b_c2, columns = ['gbm2b_c2']),\n",
    "                         pd.DataFrame(gbm2b_c3, columns = ['gbm2b_c3'])],\n",
    "                    axis = 1)\n",
    "\n",
    "preds_test.to_csv('./output/preds_test.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
